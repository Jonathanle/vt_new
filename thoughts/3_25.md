

# Objectives
- I will explain what I have been working on in context to model building
- From this I will identify what issues I have with the program that lead to a loss of performance


# 3_25 Insights 
Recently I just completed the validation loop so that I can test, regarding ensuring that my model is validated to be efficient I encountered problems preventing me from obtaining a high validation score: 

1. Why is the validation AUC so low? 
    I realized that eventhough my training AUC is very high, my validation AUC is low. I began questioning that it could be due to the facte that I have the wrong kind of metric that I measure, but given that there is a sense of high variability and good performance in ECG, I highly suspect that it is not that issue.



1. I began on thinking on how the data itself could be the issue, this seems like a real possibility. Like given that the data I am feeding to the model is solely annotations, is it possible that the data annotations is the possibility?
    - I don't really think so because I saw that Derek was able to use the radiomics feature to feed the LGE through the models in order to  use that information to reduce uncertainty about the binary outcome associated with the patient. This is something that I saw as really uuseful.
    - another interpretation from the information field is that for any information set I have, whether there exists a fucntion such that the equivalence in the output is clear; I can transform the data into a specific belief distribution. 

2. Option 2 - The features that the NN tries to create are too overfit. I see this option as more likely among all the options and something worth investigating. When I see the training AUC, it heavily suggests that the performance of it is very high on training sets and low on validation sets, especially with my CV validation approach, it is very hard to determine how to do this
    


